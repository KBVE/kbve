---
apiVersion: v1
kind: ConfigMap
metadata:
  name: vector-config
  namespace: vector
data:
  vector.yml: |
    api:
      enabled: true
      address: 0.0.0.0:9001

    sources:
      kubernetes_logs:
        type: kubernetes_logs
        self_node_name: "${VECTOR_SELF_NODE_NAME}"
        extra_namespace_label_selector: "kubernetes.io/metadata.name=kilobase"
        exclude_paths_glob_patterns:
          - "**/supabase-vector-*/**"
          - "**/vector/**"
        auto_partial_merge: true
        data_dir: "/vector-data-dir"

    transforms:
      project_logs:
        type: remap
        inputs:
          - kubernetes_logs
        source: |-
          .project = "default"
          .event_message = del(.message)
          .appname = del(.container_name)
          del(.container_created_at)
          del(.container_id)
          del(.source_type)
          del(.stream)
          del(.label)
          del(.image)
          del(.host)
          del(.stream)
      router:
        type: route
        inputs:
          - project_logs
        route:
          kong: '.appname == "supabase-kong" || .appname == "kong-kong" || .appname == "proxy"'
          auth: '.appname == "supabase-auth" || .appname == "gotrue"'
          rest: '.appname == "supabase-rest" || .appname == "postgrest"'
          realtime: '.appname == "supabase-realtime" || .appname == "realtime"'
          storage: '.appname == "supabase-storage" || .appname == "storage"'
          functions: '.appname == "supabase-functions" || .appname == "functions"'
          db: '.appname == "supabase-db" || .appname == "postgres"'
          analytics: '.appname == "logflare" || .appname == "supabase-analytics"'
          meta: '.appname == "postgres-meta" || .appname == "supabase-meta"'
          studio: '.appname == "studio" || .appname == "supabase-studio"'
      kong_logs:
        type: remap
        inputs:
          - router.kong
        source: |-
          req, err = parse_nginx_log(.event_message, "combined")
          if err == null {
              .timestamp = req.timestamp
              .metadata.request.headers.referer = req.referer
              .metadata.request.headers.user_agent = req.agent
              .metadata.request.headers.cf_connecting_ip = req.client
              .metadata.request.method = req.method
              .metadata.request.path = req.path
              .metadata.request.protocol = req.protocol
              .metadata.response.status_code = req.status
          }
          if err != null {
            abort
          }
      kong_err:
        type: remap
        inputs:
          - router.kong
        source: |-
          .metadata.request.method = "GET"
          .metadata.response.status_code = 200
          parsed, err = parse_nginx_log(.event_message, "error")
          if err == null {
              .timestamp = parsed.timestamp
              .severity = parsed.severity
              .metadata.request.host = parsed.host
              .metadata.request.headers.cf_connecting_ip = parsed.client
              url, err = split(parsed.request, " ")
              if err == null {
                  .metadata.request.method = url[0]
                  .metadata.request.path = url[1]
                  .metadata.request.protocol = url[2]
              }
          }
          if err != null {
            abort
          }
      auth_logs:
        type: remap
        inputs:
          - router.auth
        source: |-
          parsed, err = parse_json(.event_message)
          if err == null {
              .metadata.timestamp = parsed.time
              .metadata = merge!(.metadata, parsed)
          }
      rest_logs:
        type: remap
        inputs:
          - router.rest
        source: |-
          parsed, err = parse_regex(.event_message, r'^(?P<time>.*): (?P<msg>.*)')
          if err == null {
              .event_message = parsed.msg
              .timestamp = parse_timestamp!(parsed.time, "%+")
              .metadata.host = .project
          }
      realtime_logs:
        type: remap
        inputs:
          - router.realtime
        source: |-
          .metadata.project = del(.project)
          .metadata.external_id = .metadata.project
          parsed, err = parse_regex(.event_message, r'^(?P<time>\d+:\d+:\d+\.\d+) \[(?P<level>\w+)\] (?P<msg>.*)')
          if err == null {
              .event_message = parsed.msg
              .metadata.level = parsed.level
          }
      storage_logs:
        type: remap
        inputs:
          - router.storage
        source: |-
          .metadata.project = del(.project)
          .metadata.tenantId = .metadata.project
          parsed, err = parse_json(.event_message)
          if err == null {
              .event_message = parsed.msg
              .metadata.level = parsed.level
              .metadata.timestamp = parsed.time
              .metadata.context[0].host = parsed.hostname
              .metadata.context[0].pid = parsed.pid
          }
      db_logs:
        type: remap
        inputs:
          - router.db
        source: |-
          .metadata.host = "db-default"
          .metadata.parsed.timestamp = .timestamp

          parsed, err = parse_regex(.event_message, r'.*(?P<level>INFO|NOTICE|WARNING|ERROR|LOG|FATAL|PANIC?):.*', numeric_groups: true)

          if err != null || parsed == null {
            .metadata.parsed.error_severity = "info"
          }
          if parsed != null {
           .metadata.parsed.error_severity = parsed.level
          }
          if .metadata.parsed.error_severity == "info" {
              .metadata.parsed.error_severity = "log"
          }
          .metadata.parsed.error_severity = upcase!(.metadata.parsed.error_severity)
      
      analytics_logs:
        type: remap
        inputs:
          - router.analytics
        source: |-
          .metadata.service = "analytics"
          parsed, err = parse_json(.event_message)
          if err == null {
              .metadata = merge!(.metadata, parsed)
          }
      
      meta_logs:
        type: remap
        inputs:
          - router.meta
        source: |-
          .metadata.service = "meta"
          parsed, err = parse_json(.event_message)
          if err == null {
              .metadata = merge!(.metadata, parsed)
          }
      
      studio_logs:
        type: remap
        inputs:
          - router.studio
        source: |-
          .metadata.service = "studio"
          .metadata.host = .project

    sinks:
      logflare_auth:
        type: 'http'
        inputs:
          - auth_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=gotrue.logs.prod'
      logflare_realtime:
        type: 'http'
        inputs:
          - realtime_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=realtime.logs.prod'
      logflare_rest:
        type: 'http'
        inputs:
          - rest_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=postgREST.logs.prod'
      logflare_db:
        type: 'http'
        inputs:
          - db_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://kong.kilobase.svc.cluster.local:8000/analytics/v1/api/logs?source_name=postgres.logs'
      logflare_functions:
        type: 'http'
        inputs:
          - router.functions
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=deno-relay-logs'
      logflare_storage:
        type: 'http'
        inputs:
          - storage_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=storage.logs.prod.2'
      logflare_kong:
        type: 'http'
        inputs:
          - kong_logs
          - kong_err
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=cloudflare.logs.prod'
      
      logflare_analytics:
        type: 'http'
        inputs:
          - analytics_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=analytics.logs.prod'
      
      logflare_meta:
        type: 'http'
        inputs:
          - meta_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=meta.logs.prod'
      
      logflare_studio:
        type: 'http'
        inputs:
          - studio_logs
        encoding:
          codec: 'json'
        method: 'post'
        request:
          retry_max_duration_secs: 10
          headers:
            x-api-key: ${LOGFLARE_PUBLIC_ACCESS_TOKEN?LOGFLARE_PUBLIC_ACCESS_TOKEN is required}
        uri: 'http://analytics.kilobase.svc.cluster.local:4000/api/logs?source_name=studio.logs.prod'